{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images Classification\n",
    "#### Multi-Layer Perceptron (MLP) / Neuron Nets\n",
    "\n",
    "[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) is the dataset we are using for this assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# X dim = 50000*3072\n",
    "# Y dim = 50000*1\n",
    "X = np.empty([0,3072])\n",
    "Y = np.empty([0,1])\n",
    "for i in range(1,6):\n",
    "    file = \"C:/Users/Donghan/Desktop/cifar-10-batches-py/data_batch_{}\".format(i)\n",
    "    dicts = unpickle(file)\n",
    "    X = np.append(X, dicts[b'data'], axis = 0)\n",
    "    Y = np.append(Y, np.expand_dims(dicts[b'labels'], axis = 1), axis = 0)\n",
    "# print(X)\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "file_test = \"C:/Users/Donghan/Desktop/cifar-10-batches-py/test_batch\"\n",
    "X_test = unpickle(file_test)[b'data']\n",
    "Y_test = unpickle(file_test)[b'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function for forward and backward layer\n",
    "\n",
    "Options:\n",
    "* sigmoid\n",
    "* relu\n",
    "* leaky_relu\n",
    "* softmax\n",
    "\n",
    "Others are not supported yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1 + np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def leaky_relu(Z):\n",
    "    return np.where(Z > 0, Z, Z * 0.01)\n",
    "    \n",
    "def leaky_relu_back(dl, Z, alpha=0.01):\n",
    "    dx = np.ones_like(Z)\n",
    "    dx[Z < 0] = alpha\n",
    "    return dx*dl\n",
    "    \n",
    "def sigmoid_back(dA, Z):\n",
    "    return dA * sigmoid(Z) * (1 - sigmoid(Z))\n",
    "\n",
    "def relu_back(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    np.squeeze(dZ)[np.squeeze(Z) <= 0] = 0;\n",
    "    return dZ\n",
    "\n",
    "def logsumexp(Z):    \n",
    "    Zmax = np.max(Z,axis=1)[:, None]    \n",
    "    lse = Zmax + np.log(np.sum(np.exp(Z - Zmax), axis=1))[:, None]    \n",
    "    return lse #N    \n",
    "\n",
    "def softmax(\n",
    "    u, # N x C\n",
    "    ):\n",
    "    u_exp = np.exp(u - np.max(u, 1)[:, None])\n",
    "    return u_exp / np.sum(u_exp, axis=-1)[:, None]\n",
    "\n",
    "def softmax_back(dA, u):\n",
    "    return dA * softmax(u) * (1-softmax(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X,#N x D              \n",
    "              Y,#N x K              \n",
    "              W,#M x K               \n",
    "              V,#D x M             \n",
    "             ):\n",
    "    Z = logistic(np.dot(X, V))#N x M  \n",
    "    N,D = X.shape    \n",
    "    Yh = softmax(np.dot(Z, W))#N x K    \n",
    "    dY = Yh - Y #N x K\n",
    "    dW= np.dot(Z.T, dY)/N #M x K   \n",
    "    dZ = np.dot(dY, W.T) #N x M    \n",
    "    dV = np.dot(X.T, dZ * Z * (1 - Z))/N #D x M \n",
    "    return dW, dV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(X, Y, M, lr=.1, eps=1e-9, max_iters=100000):\n",
    "    N, D = X.shape\n",
    "    N,K = Y.shape\n",
    "    W = np.random.randn(M, K)*.01\n",
    "    V = np.random.randn(D, M)*.01\n",
    "    dW = np.inf*np.ones_like(W)\n",
    "    t = 0\n",
    "    while np.linalg.norm(dW) > eps and t < max_iters:\n",
    "        dW, dV = gradients(X, Y, W, V)        \n",
    "        W = W - lr*dW       \n",
    "        V = V - lr*dV\n",
    "        t+=1\n",
    "    return W,V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron Network\n",
    "#### Initialize the layer dimension and weights, bias\n",
    "\n",
    "Weight Initialization technique refers to [Delving Deep into Rectifiers:\n",
    "Surpassing Human-Level Performance on ImageNet Classification\n",
    "](https://arxiv.org/pdf/1502.01852.pdf)\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*zxD6Nr6TyAb8JEG6oXAjkg.png)\n",
    "\n",
    "* Speed up training\n",
    "* Avoid gradient vanishing/exploding (No zero/inf in the computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(input_dim, out_dim, batch_size):\n",
    "    return np.random.randn(\n",
    "            input_dim, out_dim) * np.sqrt(2/out_dim), np.zeros(out_dim)\n",
    "\n",
    "def init_weight_bias(layer_dim):\n",
    "    W = []\n",
    "    b = []\n",
    "    for i in layer_dim:\n",
    "        weight, bias = init_layers(i[0],i[1],batch_size)\n",
    "        W.append(weight)\n",
    "        b.append(bias)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forward_layers:\n",
    "    '''\n",
    "    First forward layer:\n",
    "    A_prev = X\n",
    "    '''    \n",
    "    def __init__(self, layer):\n",
    "        self.W = layer[\"weights\"]\n",
    "        self.b = layer[\"bias\"]\n",
    "        self.activation = layer[\"activations\"]\n",
    "        self.layer_dim = layer[\"layer_dim\"]\n",
    "        self.num_layer = len(self.layer_dim)\n",
    "        \n",
    "    def fit(self, A_prev, W, b, activation):\n",
    "        Z_curr = np.dot(A_prev, W) + b\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            activation = relu\n",
    "        elif activation == \"sigmoid\":\n",
    "            activation = sigmoid\n",
    "        elif activation == \"leaky_relu\":\n",
    "            activation = leaky_relu\n",
    "        elif activation == \"softmax\":\n",
    "            activation = softmax\n",
    "        else:\n",
    "            print(\"This activation function is not supported\")\n",
    "            return\n",
    "            \n",
    "        return activation(Z_curr), Z_curr\n",
    "    \n",
    "    def forward(self, X):\n",
    "        memory_A = []\n",
    "        memory_Z = []\n",
    "        A_curr = X\n",
    "        # Loop over the all layers and update the Y_h/A_curr for each layer\n",
    "        for i in range(self.num_layer):\n",
    "            A_prev = A_curr\n",
    "            if i == self.num_layer - 1:\n",
    "                # A_curr is also Y_h\n",
    "                A_curr, Z_curr = self.fit(A_prev, self.W[-1], self.b[-1], self.activation[-1])\n",
    "            else:\n",
    "                A_curr, Z_curr = self.fit(A_prev, self.W[i], self.b[i], self.activation[i])\n",
    "\n",
    "            memory_A.append(A_prev)\n",
    "            memory_Z.append(Z_curr)\n",
    "            \n",
    "        return A_curr, Z_curr, memory_A, memory_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backward_layers:\n",
    "    def __init__(self,layer):\n",
    "        self.activation = layer[\"activations\"]\n",
    "        self.layer_dim = layer[\"layer_dim\"]\n",
    "        self.num_layer = len(self.layer_dim)\n",
    "    \n",
    "    def fit(self, dA_curr, W_curr, b_curr, Z_curr, A_prev, activation_back):\n",
    "        N,D = A_prev.shape\n",
    "\n",
    "        if activation_back == \"relu\":\n",
    "            activation_back = relu_back\n",
    "        elif activation_back == \"sigmoid\":\n",
    "            activation_back = sigmoid_back\n",
    "        elif activation_back == \"leaky_relu\":\n",
    "            activation_back = leaky_relu_back\n",
    "        elif activation_back == \"softmax\":\n",
    "            activation_back = softmax_back\n",
    "        else:\n",
    "            raise ValueError(\"This activation function is not supported\")\n",
    "        \n",
    "        # Get the gradient\n",
    "        dZ_curr = activation_back(dA_curr, Z_curr)\n",
    "        dW_curr = np.dot(A_prev.T, dZ_curr) / N\n",
    "        db_curr = np.sum(dZ_curr.T, axis=1) / N\n",
    "        dA_prev = np.dot(dZ_curr, W_curr.T)\n",
    "        \n",
    "        return dA_prev, dW_curr, db_curr\n",
    "    \n",
    "    def backward(self, Y_h, Y,memory_W, memory_b, memory_A, memory_Z):\n",
    "        if np.count_nonzero(Y_h) == 0:\n",
    "            print (Y_h)\n",
    "        dA_prev = - (np.divide(Y, Y_h) - np.divide(1 - Y, 1 - Y_h))\n",
    "        gradient_W = []\n",
    "        gradient_b = []\n",
    "        # Loop backward to get the gradient for each layer\n",
    "        for i in range(self.num_layer):\n",
    "            # Since backward layer, loop from the last element in the memory list\n",
    "            dA_curr = dA_prev\n",
    "            W_curr = memory_W[-i-1]\n",
    "            b_curr = memory_b[-i-1]\n",
    "            Z_curr = memory_Z[-i-1]\n",
    "            A_prev = memory_A[-i-1]\n",
    "            # Same as above\n",
    "            if i == 0:\n",
    "                dA_prev, dW_curr, db_curr = self.fit(dA_curr, W_curr, \\\n",
    "                                                    b_curr, Z_curr, A_prev, self.activation[-1])\n",
    "            else:\n",
    "                dA_prev, dW_curr, db_curr = self.fit(dA_curr, W_curr, \\\n",
    "                                                    b_curr, Z_curr, A_prev, self.activation[-i-1])\n",
    "            gradient_W.append(dW_curr)\n",
    "            gradient_b.append(db_curr)\n",
    "        return gradient_W, gradient_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - The Combination of Forward and Backward layers\n",
    "\n",
    "**Dataflow and General Procedure:**\n",
    "\n",
    "1. Initialize the ***weight and bias*** by given of the predefined layer dimension\n",
    "2. Input feature ***data*** and ***labels***\n",
    "3. Forward the data in ***Forward layers***\n",
    "4. Obtain the ***Y_hat and memories of Y_hat*** for previous forward layers\n",
    "5. Pass the memories of Y_hat and initialized weight and bias into backward layer for ***backparagation***\n",
    "6. ***Update the weight and bias*** by the calculated gradients (use gradient descent)\n",
    "7. ***Loop*** over all the mini-batches\n",
    "\n",
    "### Methods\n",
    "\n",
    "* **fit(X,Y)** - Train the model by given of X/input, Y/labels\n",
    "\n",
    "* **predict(X)** - Get the prediction class by given of X\n",
    "\n",
    "* **predict_prob(X)** - Get the prediction probabilities by given of X\n",
    "\n",
    "* **score(X,Y)** - Return the accuracy score by given of X/input, Y/labels\n",
    "\n",
    "* **cost(X,Y)** - Cross-entropy cost function, return the prediction-true loss\n",
    "\n",
    "### Attributes\n",
    "\n",
    "* **attributes()** - Return the Weight, Bias, Layer_dim, Activation for the current neuron net\n",
    "\n",
    "### Options\n",
    "\n",
    "* **clip_gradient** - Clip the gradient by defined minimum and maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(Forward_layers, Backward_layers):\n",
    "    def __init__(self, layer, clip_gradient_value = None):\n",
    "        super().__init__(layer)\n",
    "        self.layer = layer\n",
    "        self.clip_gradient_value = clip_gradient_value\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        forward = Forward_layers(self.layer)\n",
    "        A_curr, Z_curr, memory_A, memory_Z = forward.forward(X)\n",
    "        Y_h = A_curr\n",
    "        backward = Backward_layers(self.layer)\n",
    "        gradient_W, gradient_b = backward.backward(Y_h, Y,memory_W, memory_b, memory_A, memory_Z)\n",
    "        for i in range(len(self.layer_dim)):\n",
    "            if self.clip_gradient_value is not None:\n",
    "                self.layer[\"weights\"][-i-1] -= lr*np.clip(gradient_W[i],-self.clip_gradient_value, self.clip_gradient_value) \n",
    "                self.layer[\"bias\"][-i-1] -= lr*np.clip(gradient_b[i],-self.clip_gradient_value, self.clip_gradient_value) \n",
    "            else:\n",
    "                self.layer[\"weights\"][-i-1] -= lr*gradient_W[i]  \n",
    "                self.layer[\"bias\"][-i-1] -= lr*gradient_b[i]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        forward = Forward_layers(self.layer)\n",
    "        A_curr, _,_,_ = forward.forward(X)\n",
    "        return A_curr\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''Return probabilities of class'''\n",
    "        Y_h_prob = self.forward(X)\n",
    "        return np.where(softmax(Y_h_prob) >= np.expand_dims(np.max(softmax(Y_h_prob), \\\n",
    "                                                                   axis = 1), axis = 1), 1, 0)\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def attributes(self):\n",
    "        return dict(zip([\"Weight\",\"Bias\",\"Layer_dim\",\"Activation\"],[self.layer[\"weights\"],\\\n",
    "                                                                    self.layer[\"bias\"],\\\n",
    "                                                                    self.layer[\"layer_dim\"],\\\n",
    "                                                                    self.layer[\"activations\"]]))\n",
    "    def score(self, X, Y):\n",
    "        Y_h_prob = self.forward(X)\n",
    "        Y_h_class = np.where(softmax(Y_h_prob) >= np.expand_dims(np.max(softmax(Y_h_prob), \\\n",
    "                                                                        axis = 1), axis = 1), 1, 0)\n",
    "        return np.mean([True if (Y_h_class[i] == Y[i]).all() else False for i in range(len(Y))])\n",
    "    \n",
    "    def cost(self, X, Y):\n",
    "        Y_h_prob = self.forward(X)\n",
    "        nll = - np.mean(np.sum(Y_h_prob*Y, 1) - logsumexp(Y_h_prob))\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Normalize image data\n",
    "* speed up training (rescales the values into a range of [0,1])\n",
    "* higher accuracy - lower loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = Normalizer()\n",
    "Y = np.array(pd.get_dummies(np.squeeze(Y)))\n",
    "X = norm.fit_transform(X)\n",
    "\n",
    "X_test = norm.fit_transform(X_test)\n",
    "Y_test = np.array(pd.get_dummies(np.squeeze(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for training\n",
    "\n",
    "Stochastic gradient descent mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X, Y, batch_size):\n",
    "    for i in np.arange(0, X.shape[0], batch_size):\n",
    "        # Avoid last batch != batch_size\n",
    "        if X[i:i + batch_size].shape[0] == batch_size:\n",
    "            yield (X[i:i + batch_size], Y[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the NN\n",
    "#### Take 2 hidden layers as example \n",
    "\n",
    "* Initialize weight, bias and define *layer* \n",
    "* Initialize *batch_size*, *epochs*, and *lr/learning_rate*\n",
    "* Initialize Neuron Net (ANN)\n",
    "* Split input data to training and validation dataset\n",
    "* Loop/training start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d229b61309524a83b268ead095273acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Minibatch Loss= 2.2992, Training Accuracy= 0.147\n",
      "Validation: Step 0, Minibatch Loss= 2.2963, Validation Accuracy= 0.182\n",
      "Step 50, Minibatch Loss= 2.1884, Training Accuracy= 0.380\n",
      "Validation: Step 50, Minibatch Loss= 2.1934, Validation Accuracy= 0.361\n",
      "Step 100, Minibatch Loss= 2.1584, Training Accuracy= 0.413\n",
      "Validation: Step 100, Minibatch Loss= 2.1657, Validation Accuracy= 0.388\n",
      "Step 150, Minibatch Loss= 2.1374, Training Accuracy= 0.438\n",
      "Validation: Step 150, Minibatch Loss= 2.1468, Validation Accuracy= 0.411\n",
      "Step 200, Minibatch Loss= 2.1188, Training Accuracy= 0.458\n",
      "Validation: Step 200, Minibatch Loss= 2.1307, Validation Accuracy= 0.426\n",
      "Step 250, Minibatch Loss= 2.1024, Training Accuracy= 0.477\n",
      "Validation: Step 250, Minibatch Loss= 2.1167, Validation Accuracy= 0.438\n",
      "Step 300, Minibatch Loss= 2.0876, Training Accuracy= 0.492\n",
      "Validation: Step 300, Minibatch Loss= 2.1044, Validation Accuracy= 0.449\n",
      "Step 350, Minibatch Loss= 2.0743, Training Accuracy= 0.506\n",
      "Validation: Step 350, Minibatch Loss= 2.0938, Validation Accuracy= 0.456\n",
      "Step 400, Minibatch Loss= 2.0619, Training Accuracy= 0.519\n",
      "Validation: Step 400, Minibatch Loss= 2.0843, Validation Accuracy= 0.462\n",
      "Step 450, Minibatch Loss= 2.0504, Training Accuracy= 0.531\n",
      "Validation: Step 450, Minibatch Loss= 2.0758, Validation Accuracy= 0.472\n",
      "Step 500, Minibatch Loss= 2.0396, Training Accuracy= 0.542\n",
      "Validation: Step 500, Minibatch Loss= 2.0683, Validation Accuracy= 0.478\n",
      "Step 550, Minibatch Loss= 2.0294, Training Accuracy= 0.551\n",
      "Validation: Step 550, Minibatch Loss= 2.0616, Validation Accuracy= 0.482\n",
      "Step 600, Minibatch Loss= 2.0197, Training Accuracy= 0.561\n",
      "Validation: Step 600, Minibatch Loss= 2.0555, Validation Accuracy= 0.487\n",
      "Step 650, Minibatch Loss= 2.0104, Training Accuracy= 0.570\n",
      "Validation: Step 650, Minibatch Loss= 2.0500, Validation Accuracy= 0.492\n",
      "Step 700, Minibatch Loss= 2.0014, Training Accuracy= 0.579\n",
      "Validation: Step 700, Minibatch Loss= 2.0448, Validation Accuracy= 0.498\n",
      "Step 750, Minibatch Loss= 1.9927, Training Accuracy= 0.588\n",
      "Validation: Step 750, Minibatch Loss= 2.0399, Validation Accuracy= 0.502\n",
      "Step 800, Minibatch Loss= 1.9843, Training Accuracy= 0.596\n",
      "Validation: Step 800, Minibatch Loss= 2.0356, Validation Accuracy= 0.503\n",
      "Step 850, Minibatch Loss= 1.9760, Training Accuracy= 0.605\n",
      "Validation: Step 850, Minibatch Loss= 2.0316, Validation Accuracy= 0.505\n",
      "Step 900, Minibatch Loss= 1.9679, Training Accuracy= 0.614\n",
      "Validation: Step 900, Minibatch Loss= 2.0277, Validation Accuracy= 0.509\n",
      "Step 950, Minibatch Loss= 1.9599, Training Accuracy= 0.622\n",
      "Validation: Step 950, Minibatch Loss= 2.0243, Validation Accuracy= 0.510\n",
      "Step 1000, Minibatch Loss= 1.9521, Training Accuracy= 0.629\n",
      "Validation: Step 1000, Minibatch Loss= 2.0212, Validation Accuracy= 0.513\n",
      "Step 1050, Minibatch Loss= 1.9444, Training Accuracy= 0.637\n",
      "Validation: Step 1050, Minibatch Loss= 2.0185, Validation Accuracy= 0.514\n",
      "Step 1100, Minibatch Loss= 1.9369, Training Accuracy= 0.645\n",
      "Validation: Step 1100, Minibatch Loss= 2.0158, Validation Accuracy= 0.513\n",
      "Step 1150, Minibatch Loss= 1.9296, Training Accuracy= 0.653\n",
      "Validation: Step 1150, Minibatch Loss= 2.0133, Validation Accuracy= 0.513\n",
      "Step 1200, Minibatch Loss= 1.9223, Training Accuracy= 0.660\n",
      "Validation: Step 1200, Minibatch Loss= 2.0109, Validation Accuracy= 0.513\n",
      "Step 1250, Minibatch Loss= 1.9152, Training Accuracy= 0.667\n",
      "Validation: Step 1250, Minibatch Loss= 2.0085, Validation Accuracy= 0.512\n",
      "Step 1300, Minibatch Loss= 1.9083, Training Accuracy= 0.672\n",
      "Validation: Step 1300, Minibatch Loss= 2.0065, Validation Accuracy= 0.513\n",
      "Step 1350, Minibatch Loss= 1.9018, Training Accuracy= 0.678\n",
      "Validation: Step 1350, Minibatch Loss= 2.0051, Validation Accuracy= 0.514\n",
      "Step 1400, Minibatch Loss= 1.8957, Training Accuracy= 0.683\n",
      "Validation: Step 1400, Minibatch Loss= 2.0048, Validation Accuracy= 0.517\n",
      "Step 1450, Minibatch Loss= 1.8896, Training Accuracy= 0.687\n",
      "Validation: Step 1450, Minibatch Loss= 2.0030, Validation Accuracy= 0.516\n",
      "Step 1500, Minibatch Loss= 1.8832, Training Accuracy= 0.694\n",
      "Validation: Step 1500, Minibatch Loss= 1.9976, Validation Accuracy= 0.514\n",
      "Step 1550, Minibatch Loss= 1.8772, Training Accuracy= 0.697\n",
      "Validation: Step 1550, Minibatch Loss= 1.9988, Validation Accuracy= 0.516\n",
      "Step 1600, Minibatch Loss= 1.8716, Training Accuracy= 0.702\n",
      "Validation: Step 1600, Minibatch Loss= 1.9970, Validation Accuracy= 0.515\n",
      "Step 1650, Minibatch Loss= 1.8644, Training Accuracy= 0.710\n",
      "Validation: Step 1650, Minibatch Loss= 1.9950, Validation Accuracy= 0.515\n",
      "Step 1700, Minibatch Loss= 1.8597, Training Accuracy= 0.713\n",
      "Validation: Step 1700, Minibatch Loss= 1.9944, Validation Accuracy= 0.513\n",
      "Step 1750, Minibatch Loss= 1.8533, Training Accuracy= 0.720\n",
      "Validation: Step 1750, Minibatch Loss= 1.9932, Validation Accuracy= 0.514\n",
      "Step 1800, Minibatch Loss= 1.8466, Training Accuracy= 0.727\n",
      "Validation: Step 1800, Minibatch Loss= 1.9919, Validation Accuracy= 0.512\n",
      "Step 1850, Minibatch Loss= 1.8428, Training Accuracy= 0.727\n",
      "Validation: Step 1850, Minibatch Loss= 1.9899, Validation Accuracy= 0.512\n",
      "Step 1900, Minibatch Loss= 1.8368, Training Accuracy= 0.733\n",
      "Validation: Step 1900, Minibatch Loss= 1.9869, Validation Accuracy= 0.512\n",
      "Step 1950, Minibatch Loss= 1.8298, Training Accuracy= 0.742\n",
      "Validation: Step 1950, Minibatch Loss= 1.9870, Validation Accuracy= 0.509\n",
      "Step 2000, Minibatch Loss= 1.8272, Training Accuracy= 0.740\n",
      "Validation: Step 2000, Minibatch Loss= 1.9871, Validation Accuracy= 0.509\n",
      "Step 2050, Minibatch Loss= 1.8220, Training Accuracy= 0.745\n",
      "Validation: Step 2050, Minibatch Loss= 1.9862, Validation Accuracy= 0.507\n",
      "Step 2100, Minibatch Loss= 1.8149, Training Accuracy= 0.752\n",
      "Validation: Step 2100, Minibatch Loss= 1.9870, Validation Accuracy= 0.506\n",
      "Step 2150, Minibatch Loss= 1.8100, Training Accuracy= 0.758\n",
      "Validation: Step 2150, Minibatch Loss= 1.9880, Validation Accuracy= 0.504\n",
      "Step 2200, Minibatch Loss= 1.8060, Training Accuracy= 0.759\n",
      "Validation: Step 2200, Minibatch Loss= 1.9857, Validation Accuracy= 0.504\n",
      "Step 2250, Minibatch Loss= 1.7992, Training Accuracy= 0.766\n",
      "Validation: Step 2250, Minibatch Loss= 1.9834, Validation Accuracy= 0.504\n",
      "Step 2300, Minibatch Loss= 1.7936, Training Accuracy= 0.772\n",
      "Validation: Step 2300, Minibatch Loss= 1.9859, Validation Accuracy= 0.498\n",
      "Step 2350, Minibatch Loss= 1.7928, Training Accuracy= 0.770\n",
      "Validation: Step 2350, Minibatch Loss= 1.9856, Validation Accuracy= 0.498\n",
      "Step 2400, Minibatch Loss= 1.7862, Training Accuracy= 0.776\n",
      "Validation: Step 2400, Minibatch Loss= 1.9855, Validation Accuracy= 0.498\n",
      "Step 2450, Minibatch Loss= 1.7821, Training Accuracy= 0.779\n",
      "Validation: Step 2450, Minibatch Loss= 1.9857, Validation Accuracy= 0.494\n",
      "Step 2500, Minibatch Loss= 1.7798, Training Accuracy= 0.777\n",
      "Validation: Step 2500, Minibatch Loss= 1.9800, Validation Accuracy= 0.501\n",
      "Step 2550, Minibatch Loss= 1.7725, Training Accuracy= 0.786\n",
      "Validation: Step 2550, Minibatch Loss= 1.9814, Validation Accuracy= 0.498\n",
      "Step 2600, Minibatch Loss= 1.7676, Training Accuracy= 0.792\n",
      "Validation: Step 2600, Minibatch Loss= 1.9815, Validation Accuracy= 0.495\n",
      "Step 2650, Minibatch Loss= 1.7614, Training Accuracy= 0.798\n",
      "Validation: Step 2650, Minibatch Loss= 1.9795, Validation Accuracy= 0.497\n",
      "Step 2700, Minibatch Loss= 1.7595, Training Accuracy= 0.795\n",
      "Validation: Step 2700, Minibatch Loss= 1.9852, Validation Accuracy= 0.488\n",
      "Step 2750, Minibatch Loss= 1.7567, Training Accuracy= 0.797\n",
      "Validation: Step 2750, Minibatch Loss= 1.9848, Validation Accuracy= 0.491\n",
      "Step 2800, Minibatch Loss= 1.7487, Training Accuracy= 0.806\n",
      "Validation: Step 2800, Minibatch Loss= 1.9814, Validation Accuracy= 0.490\n",
      "Step 2850, Minibatch Loss= 1.7451, Training Accuracy= 0.807\n",
      "Validation: Step 2850, Minibatch Loss= 1.9840, Validation Accuracy= 0.489\n",
      "Step 2900, Minibatch Loss= 1.7463, Training Accuracy= 0.806\n",
      "Validation: Step 2900, Minibatch Loss= 1.9933, Validation Accuracy= 0.479\n",
      "Step 2950, Minibatch Loss= 1.7345, Training Accuracy= 0.819\n",
      "Validation: Step 2950, Minibatch Loss= 1.9780, Validation Accuracy= 0.496\n",
      "Step 3000, Minibatch Loss= 1.7285, Training Accuracy= 0.824\n",
      "Validation: Step 3000, Minibatch Loss= 1.9800, Validation Accuracy= 0.496\n",
      "Step 3050, Minibatch Loss= 1.7323, Training Accuracy= 0.818\n",
      "Validation: Step 3050, Minibatch Loss= 1.9774, Validation Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3100, Minibatch Loss= 1.7267, Training Accuracy= 0.821\n",
      "Validation: Step 3100, Minibatch Loss= 1.9783, Validation Accuracy= 0.494\n",
      "Step 3150, Minibatch Loss= 1.7221, Training Accuracy= 0.826\n",
      "Validation: Step 3150, Minibatch Loss= 1.9784, Validation Accuracy= 0.494\n",
      "Step 3200, Minibatch Loss= 1.7215, Training Accuracy= 0.825\n",
      "Validation: Step 3200, Minibatch Loss= 1.9789, Validation Accuracy= 0.494\n",
      "Step 3250, Minibatch Loss= 1.7133, Training Accuracy= 0.833\n",
      "Validation: Step 3250, Minibatch Loss= 1.9823, Validation Accuracy= 0.481\n",
      "Step 3300, Minibatch Loss= 1.7083, Training Accuracy= 0.839\n",
      "Validation: Step 3300, Minibatch Loss= 1.9769, Validation Accuracy= 0.495\n",
      "Step 3350, Minibatch Loss= 1.7096, Training Accuracy= 0.835\n",
      "Validation: Step 3350, Minibatch Loss= 1.9781, Validation Accuracy= 0.493\n",
      "Step 3400, Minibatch Loss= 1.7023, Training Accuracy= 0.842\n",
      "Validation: Step 3400, Minibatch Loss= 1.9777, Validation Accuracy= 0.490\n",
      "Step 3450, Minibatch Loss= 1.6960, Training Accuracy= 0.850\n",
      "Validation: Step 3450, Minibatch Loss= 1.9801, Validation Accuracy= 0.489\n",
      "Step 3500, Minibatch Loss= 1.6950, Training Accuracy= 0.849\n",
      "Validation: Step 3500, Minibatch Loss= 1.9815, Validation Accuracy= 0.489\n",
      "Step 3550, Minibatch Loss= 1.6882, Training Accuracy= 0.857\n",
      "Validation: Step 3550, Minibatch Loss= 1.9761, Validation Accuracy= 0.496\n",
      "Step 3600, Minibatch Loss= 1.6897, Training Accuracy= 0.852\n",
      "Validation: Step 3600, Minibatch Loss= 1.9792, Validation Accuracy= 0.488\n",
      "Step 3650, Minibatch Loss= 1.6779, Training Accuracy= 0.864\n",
      "Validation: Step 3650, Minibatch Loss= 1.9770, Validation Accuracy= 0.490\n",
      "Step 3700, Minibatch Loss= 1.6748, Training Accuracy= 0.869\n",
      "Validation: Step 3700, Minibatch Loss= 1.9780, Validation Accuracy= 0.492\n",
      "Step 3750, Minibatch Loss= 1.6721, Training Accuracy= 0.868\n",
      "Validation: Step 3750, Minibatch Loss= 1.9802, Validation Accuracy= 0.486\n",
      "Step 3800, Minibatch Loss= 1.6681, Training Accuracy= 0.872\n",
      "Validation: Step 3800, Minibatch Loss= 1.9767, Validation Accuracy= 0.491\n",
      "Step 3850, Minibatch Loss= 1.6684, Training Accuracy= 0.871\n",
      "Validation: Step 3850, Minibatch Loss= 1.9818, Validation Accuracy= 0.484\n",
      "Step 3900, Minibatch Loss= 1.6785, Training Accuracy= 0.856\n",
      "Validation: Step 3900, Minibatch Loss= 1.9754, Validation Accuracy= 0.488\n",
      "Step 3950, Minibatch Loss= 1.6582, Training Accuracy= 0.881\n",
      "Validation: Step 3950, Minibatch Loss= 1.9763, Validation Accuracy= 0.488\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Batch size, epochs, and learning rate\n",
    "batch_size = 256\n",
    "epochs = 4000\n",
    "lr = 0.01\n",
    "\n",
    "# Layers init\n",
    "layer_dim = [[3072,169],[169,64],[64,10]]\n",
    "memory_W, memory_b = init_weight_bias(layer_dim)\n",
    "\n",
    "# Take 2 hidden layers as example\n",
    "layer = {\"layer_dim\":layer_dim,\n",
    "         \"activations\":[\"relu\",\"relu\",\"relu\",\"softmax\"],\n",
    "         \"weights\":memory_W, \"bias\":memory_b}\n",
    "\n",
    "\n",
    "# Training-val dataset split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=42, shuffle = True)\n",
    "\n",
    "# loss, accuracy lists\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "accuracies_train = []\n",
    "accuracies_val = []\n",
    "\n",
    "# Init neuron net\n",
    "model = ANN(layer)\n",
    "#Option: clip_gradient = *5\n",
    "\n",
    "# Training start\n",
    "for epoch in tqdm(range(epochs)):\n",
    "        loss_train = []\n",
    "        acc_train = []\n",
    "        for batch_X, batch_Y in next_batch(X_train, y_train, batch_size):\n",
    "            model.fit(batch_X, batch_Y)\n",
    "\n",
    "            # Training loss, accuracy\n",
    "            loss_train.append(model.cost(batch_X, batch_Y))\n",
    "            acc_train.append(model.score(batch_X,batch_Y))\n",
    "\n",
    "        # Average losses, accuracy\n",
    "        losses_train.append(np.mean(loss_train))\n",
    "        accuracies_train.append(np.mean(acc_train))\n",
    "        \n",
    "        # Validation loss, accuracy\n",
    "        losses_val.append(model.cost(X_val, y_val))\n",
    "        accuracies_val.append(model.score(X_val, y_val))\n",
    "        \n",
    "        # Print loss, accuracy every 100 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Step \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(np.mean(loss_train)) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(np.mean(acc_train)))\n",
    "            print(\"Validation: \" + \"Step \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(losses_val[-1]) + \", Validation Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(accuracies_val[-1]))\n",
    "print(\"Optimization Finished!\")\n",
    "losses = {\"losses_train\":losses_train, \"losses_val\":losses_val}\n",
    "accuracies = {\"accuracies_train\":accuracies_train, \"accuracies_val\":accuracies_val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4824"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By class test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 48 %\n",
      "Accuracy of   car : 49 %\n",
      "Accuracy of  bird : 46 %\n",
      "Accuracy of   cat : 49 %\n",
      "Accuracy of  deer : 48 %\n",
      "Accuracy of   dog : 47 %\n",
      "Accuracy of  frog : 46 %\n",
      "Accuracy of horse : 49 %\n",
      "Accuracy of  ship : 50 %\n",
      "Accuracy of truck : 47 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "Y_test_class = dicts[b'labels']\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "for i in range(0, X_test.shape[0], 4):\n",
    "    images = X_test[i:i+4]\n",
    "    labels = Y_test[i:i+4]\n",
    "    predicted = model.predict(images)\n",
    "    labels_class = Y_test_class[i:i+4]\n",
    "    for j in range(4):\n",
    "        label = labels_class[j]\n",
    "        class_correct[label] += (predicted[j] == labels[j]).all()\n",
    "        class_total[label] += 1\n",
    "            \n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * (class_correct[i]) / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies[\"accuracies_val\"])\n",
    "plt.plot(accuracies[\"accuracies_train\"])\n",
    "plt.legend([\"Acc_Val\", \"Acc_Train\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[\"losses_val\"])\n",
    "plt.plot(losses[\"losses_train\"])\n",
    "plt.legend([\"Loss_Val\", \"Loss_Train\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
